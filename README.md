# ğŸ”§ Control Node Replacement - IPI Hub RDS

<div align="center">

![OpenShift](https://img.shields.io/badge/OpenShift-4.19+-red?style=for-the-badge&logo=redhat)
![Kubernetes](https://img.shields.io/badge/Kubernetes-v1.32.7-blue?style=for-the-badge&logo=kubernetes)
![Status](https://img.shields.io/badge/Status-Production_Ready-green?style=for-the-badge)

</div>

---

## ğŸ“‹ Procedure Overview Table

| Step | Section | Procedure | Time Estimate | Risk Level | Prerequisites |
|------|---------|-----------|---------------|------------|---------------|
| **1** | **ğŸ” Pre-check** | Validate current cluster state | 5 min | ğŸŸ¢ Low | Admin access |
| **2** | **ğŸ”´ ETCD Removal** | Check ETCD member status | 5 min | ğŸŸ¡ Medium | ETCD access |
| **3** | **ğŸ—‘ï¸ Member Cleanup** | Remove unhealthy ETCD member | 10 min | ğŸ”´ High | Member ID noted |
| **4** | **ğŸ”’ Quorum Guard** | Disable quorum protection | 2 min | ğŸ”´ High | Cluster stable |
| **5** | **ğŸ” Secret Cleanup** | Remove old node secrets | 5 min | ğŸŸ¡ Medium | Secret list |
| **6** | **ğŸ—ï¸ Infrastructure** | Delete machine and BMH | 5 min | ğŸŸ¡ Medium | Resource names |
| **7** | **ğŸ§¹ Node Cleanup** | Remove failed node | 10 min | ğŸŸ¡ Medium | Pod migration |
| **8** | **ğŸ”§ BMC Prep** | Prepare new bare metal node | 15 min | ğŸŸ¢ Low | BMC credentials |
| **9** | **ğŸ› ï¸ Node Config** | Create node configuration | 10 min | ğŸŸ¡ Medium | Network details |
| **10** | **ğŸ“Š BMH Monitor** | Monitor BMH provisioning | 30-60 min | ğŸŸ¢ Low | Virtual media |
| **11** | **ğŸ“œ CSR Approval** | Approve certificate requests | 5 min | ğŸŸ¢ Low | CSR monitoring |
| **12** | **ğŸ¤– Machine Link** | Create machine resource | 5 min | ğŸŸ¡ Medium | BMH ready |
| **13** | **ğŸ”— Verification** | Verify BMH-machine linking | 5 min | ğŸŸ¢ Low | Resources created |
| **14** | **âœ… Node Status** | Verify node ready status | 10 min | ğŸŸ¢ Low | Node joined |
| **15** | **ğŸ”’ Quorum Guard** | Re-enable quorum protection | 2 min | ğŸŸ¡ Medium | Node stable |
| **16** | **ğŸ§ª Final Validation** | Complete system health check | 15 min | ğŸŸ¢ Low | All components |

### ğŸ“Š Procedure Summary

| **Category** | **Details** |
|--------------|-------------|
| **ğŸ¯ Total Time** | ~2-3 hours (including provisioning) |
| **ğŸ”§ Active Time** | ~1 hour (excluding BMH provisioning) |
| **âš ï¸ Downtime** | Minimal (cluster remains operational) |
| **ğŸ›¡ï¸ Risk Level** | Medium (with proper backup) |
| **ğŸ‘¥ Required Personnel** | 1 OpenShift Administrator |
| **ğŸ“š Skill Level** | Intermediate to Advanced |

### ğŸš¨ Critical Checkpoints

| **Checkpoint** | **Validation** | **Rollback Point** |
|----------------|----------------|-------------------|
| **ETCD Health** | All endpoints responding before removal | Stop if < 2 healthy members |
| **Quorum Status** | Verify quorum guard disabled | Re-enable if issues |
| **BMH Provisioning** | Node boots and installs RHCOS | Check BMC/network config |
| **Node Join** | Node appears in cluster | Verify CSRs approved |
| **ETCD Recovery** | 3-member cluster restored | Check member list |
| **Cluster Operators** | All operators healthy | Monitor for degradation |

---

## ğŸ¯ Purpose 

> **ğŸ“‹ Objective:** This procedure demonstrates how to replace a failed Control Plane node in a Baremetal OpenShift cluster (3+0 or 3+N) using a streamlined IPI-based methodology.

This approach leverages **Infrastructure Provider Installation (IPI)** to enable rapid replacement of failed Control nodes with minimal downtime.

---

## âš¡ Prerequisites 

### ğŸ”§ System Requirements

| Requirement | Description | Status |
|-------------|-------------|---------|
| **ğŸ—ï¸ Existing Cluster** | Baremetal cluster installed with [IPI](https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/installing_on_bare_metal/installer-provisioned-infrastructure), [ABI](https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/installing_an_on-premise_cluster_with_the_agent-based_installer/index), [Assisted Installer](https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/installing_on-premise_with_assisted_installer/index), or [UPI](https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/installing_on_bare_metal/user-provisioned-infrastructure) | âœ… Required |
| **ğŸŒ DNS Records** | All required DNS records configured | âœ… Required |
| **ğŸ‘¤ Admin Access** | `cluster-admin` role access | âœ… Required |
| **ğŸ’¾ ETCD Backup** | Recent [etcd backup](https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/etcd/backing-up-and-restoring-etcd-data) taken | âœ… Required |
| **ğŸ¤– Baremetal Operator** | Available and running | âœ… Required |
| **âš™ï¸ Server Configuration** | UEFI boot mode + Redfish multimedia support | âœ… Required |
| **ğŸ“¦ OCP Version** | OpenShift >= 4.19.1 | âœ… Required |

---

## ğŸš€ Replacing a Master Node

> **ğŸ¯ Scenario:** Replacing `master-2` with `master-3` (simulating node failure by shutting down `master-2`)

### ğŸ” Pre-check Validation 

```bash
# ğŸ“Š Check current node status
$ oc get nodes
```

**Expected Output:**
```
NAME                                                   STATUS   ROLES                         AGE     VERSION
master-0.mno-cu.hubcluster-1.lab.eng.cert.redhat.com   Ready    control-plane,master,worker   4h7m    v1.32.7
master-1.mno-cu.hubcluster-1.lab.eng.cert.redhat.com   Ready    control-plane,master,worker   4h29m   v1.32.7
master-2.mno-cu.hubcluster-1.lab.eng.cert.redhat.com   Ready    control-plane,master,worker   27m     v1.32.7
```

---

## ğŸ› ï¸ Control Node Replacement Process

> **ğŸ“š Reference:** For detailed etcd member removal procedures, see [Remove Unhealthy ETCD](https://docs.openshift.com/container-platform/4.12/backup_and_restore/control_plane_backup_and_restore/replacing-unhealthy-etcd-member.html)

### ğŸ”´ Step 1: Remove Unhealthy ETCD Member (master-2)

#### ğŸ“ˆ Check ETCD Member Status

```bash
# ğŸ” List all ETCD members
$ oc -n openshift-etcd rsh etcd-master-0 etcdctl member list -w table
```

**Output:**
```
+------------------+---------+----------+----------------------------+----------------------------+------------+
|        ID        | STATUS  |   NAME   |         PEER ADDRS         |        CLIENT ADDRS        | IS LEARNER |
+------------------+---------+----------+----------------------------+----------------------------+------------+
|  c300d358075445b | started | master-0 | https://192.168.24.87:2380 | https://192.168.24.87:2379 |      false |
| 1a7b6f4c3aac9be1 | started | master-1 | https://192.168.24.88:2380 | https://192.168.24.88:2379 |      false |
| 6fd2f8909c811461 | started | master-2 | https://192.168.24.86:2380 | https://192.168.24.86:2379 |      false |
+------------------+---------+----------+----------------------------+----------------------------+------------+
```

#### ğŸ¥ Check ETCD Health Status

```bash
# ğŸ’“ Verify ETCD endpoint health
$ oc -n openshift-etcd rsh etcd-master-0 etcdctl endpoint health
```

**Expected Output (with failed node):**
```
{"level":"warn","ts":"2023-04-24T17:11:59.984Z","logger":"client","caller":"v3@v3.5.6/retry_interceptor.go:62","msg":"retrying of unary invoker failed","target":"etcd-endpoints://0xc00028c000/192.168.24.86:2379","attempt":0,"error":"rpc error: code = DeadlineExceeded desc = context deadline exceeded"}
https://192.168.24.88:2379 is healthy: successfully committed proposal: took = 7.12757ms
https://192.168.24.87:2379 is healthy: successfully committed proposal: took = 7.216856ms
https://192.168.24.86:2379 is unhealthy: failed to commit proposal: context deadline exceeded
Error: unhealthy cluster
```

> **âš ï¸ Important:** Note the `master-2` member-ID (`6fd2f8909c811461`) for the next step

#### ğŸ—‘ï¸ Remove ETCD master-2 Member

```bash
# ğŸ”§ Connect to ETCD pod and remove failed member
$ oc -n openshift-etcd rsh etcd-master-0 
sh-4.4# etcdctl member list
sh-4.4# etcdctl member remove 6fd2f8909c811461
```

**Output:**
```
Member 6fd2f8909c811461 removed from cluster c413f45f7dfe9590
```

#### âœ… Verify Member Removal

```bash
# ğŸ“‹ Confirm master-2 is no longer listed
sh-4.4# etcdctl member list -w table
```

**Expected Output:**
```
+------------------+---------+----------+----------------------------+----------------------------+------------+
|        ID        | STATUS  |   NAME   |         PEER ADDRS         |        CLIENT ADDRS        | IS LEARNER |
+------------------+---------+----------+----------------------------+----------------------------+------------+
|  c300d358075445b | started | master-0 | https://192.168.24.87:2380 | https://192.168.24.87:2379 |      false |
| 1a7b6f4c3aac9be1 | started | master-1 | https://192.168.24.88:2380 | https://192.168.24.88:2379 |      false |
+------------------+---------+----------+----------------------------+----------------------------+------------+
```

---

### ğŸ”’ Step 2: Disable Quorum Guard

> **âš ï¸ Critical:** This temporarily disables etcd quorum protection during replacement

```bash
# ğŸ›¡ï¸ Disable quorum guard for maintenance
oc patch etcd/cluster --type=merge -p '{"spec": {"unsupportedConfigOverrides": {"useUnsupportedUnsafeNonHANonProductionUnstableEtcd": true}}}'
```

---

### ğŸ” Step 3: Remove Old Secrets

#### ğŸ“‹ List Existing Secrets for master-2

```bash
# ğŸ” Find all secrets related to master-2
$ oc get secret -n openshift-etcd | grep master-2
```

**Output:**
```
etcd-peer-master-2              kubernetes.io/tls                     2      56m
etcd-serving-master-2           kubernetes.io/tls                     2      56m
etcd-serving-metrics-master-2   kubernetes.io/tls                     2      56m
```

#### ğŸ—‘ï¸ Delete Old Secrets

```bash
# ğŸ§¹ Clean up old certificates and secrets
$ oc get secrets -n openshift-etcd|grep master-2 |awk '{print $1}'|xargs oc -n openshift-etcd delete secrets
```

**Output:**
```
secret "etcd-peer-master-2" deleted
secret "etcd-serving-master-2" deleted
secret "etcd-serving-metrics-master-2" deleted
```

---

### ğŸ—ï¸ Step 4: Remove Failed Infrastructure

#### ğŸ“Š Check ETCD Pod Status

```bash
# ğŸ‘€ Monitor ETCD pod status
$ oc get pods -n openshift-etcd | grep -v etcd-quorum-guard | grep etcd
```

**Output:**
```
etcd-master-0              5/5     Running     0          54m
etcd-master-2               2/5     NotReady    0          50m
etcd-master-1               5/5     Running     0          52m
```

#### ğŸ—‘ï¸ Delete Machine and BMH Resources

```bash
# ğŸ”§ Remove machine and bare metal host objects
$ oc delete machine master-2 -n openshift-machine-api
$ oc delete bmh master-2 -n openshift-machine-api
```

#### ğŸ§¹ Clean Up Node Resources

```bash
# ğŸ‘€ Check for remaining pods on master-2
$ oc get po -A -o wide|grep master-2

# ğŸ—‘ï¸ Delete the failed node
$ oc delete node master-2

# âœ… Verify no pods remain on master-2
$ oc get po -o wide -A|grep master-2|wc -l
# Expected output: 0
```

#### ğŸ¯ Verify Current Cluster State

```bash
# ğŸ“Š Check remaining nodes
$ oc get nodes
```

**Expected Output:**
```
NAME       STATUS   ROLES                         AGE   VERSION
master-0   Ready    control-plane,master,worker   47m   v1.25.8+27e744f
master-1   Ready    control-plane,master,worker   75m   v1.25.8+27e744f
```

---

## ğŸ†• Adding the New Control Node

### ğŸ”§ Step 5: Prepare the Bare Metal Node

#### ğŸ“‹ Prerequisites for New Node

> **ğŸ’¡ Note:** The node can use either static or DHCP IP configuration. For DHCP, ensure a reservation exists.

1. **ğŸ”Œ Power State:** Ensure the new master node is powered off
2. **ğŸ”§ OC Version:** Verify `oc` client version matches cluster version  
3. **ğŸ” BMC Credentials:** Retrieve baseboard management controller credentials

#### ğŸ”‘ Encode BMC Credentials

```bash
# ğŸ” Create base64 encoded credentials
echo -ne "root" | base64      # Username
echo -ne "password" | base64  # Password
```

---

### ğŸ› ï¸ Step 6: Create Node Configuration

```yaml
# ğŸ“ Apply the complete node configuration
cat <<EOF | oc apply -f -
---
# ğŸŒ Network Configuration Secret
apiVersion: v1 
kind: Secret
metadata:
 name: master-3
 namespace: openshift-machine-api
type: Opaque
stringData:
 nmstate: | 
  interfaces: 
  - name: eno1np0
    type: ethernet
    state: up
    mac-address: b8:ce:f6:56:3d:b2
    ipv4:
      address:
      - ip: 192.168.24.89
        prefix-length: 25
      enabled: true
  dns-resolver:
    config:
      server:
      - 192.168.24.80
  routes:
    config:
    - destination: 0.0.0.0/0
      next-hop-address: 192.168.24.1
      next-hop-interface: eno1np0 
---
# ğŸ” BMC Credentials Secret
apiVersion: v1
kind: Secret
metadata:
  name: master-3-bmc
  namespace: openshift-machine-api
type: Opaque
data:
  username: cm9vdAo=      # base64 encoded username
  password: Y2FsdmluCg==  # base64 encoded password
---
# ğŸ–¥ï¸ Bare Metal Host Configuration
apiVersion: metal3.io/v1alpha1
kind: BareMetalHost
metadata:
  name: master-3.mno-cu.hubcluster-1.lab.eng.cert.redhat.com 
  namespace: openshift-machine-api
spec:
  externallyProvisioned: false
  hardwareProfile: unknown
  online: True
  bootMACAddress: b8:ce:f6:56:3d:b2 
  bmc:
    address: idrac-virtualmedia://192.168.24.157/redfish/v1/Systems/System.Embedded.1 
    credentialsName: master-3-bmc
    disableCertificateVerification: True 
  rootDeviceHints:
    deviceName: /dev/disk/by-path/pci-0000:18:00.0-scsi-0:2:1:0 
  preprovisioningNetworkDataName: master-3
  customDeploy:
    method: install_coreos
  userData:
    name: master-user-data-managed
    namespace: openshift-machine-api
EOF
```

---

### ğŸ“Š Step 7: Monitor BMH Provisioning

#### ğŸ”„ BMH State Transitions

The BMH object will progress through these states:

```mermaid
graph LR
    A[Registering] --> B[Inspecting]
    B --> C[Provisioning]
    C --> D[Provisioned]
    style A fill:#ffd700
    style B fill:#87ceeb
    style C fill:#ffa500
    style D fill:#90ee90
```

#### ğŸ‘€ Monitor Progress

```bash
# ğŸ“Š Watch BMH status progression
$ oc get bmh -w
```

**Progress Monitoring:**
```
NAME                                                   STATE         CONSUMER                ONLINE   ERROR   AGE
master-0.mno-cu.hubcluster-1.lab.eng.cert.redhat.com   unmanaged     mno-cu-8wdjc-master-0   true             4h45m
master-1.mno-cu.hubcluster-1.lab.eng.cert.redhat.com   unmanaged     mno-cu-8wdjc-master-1   true             4h45m
master-3.mno-cu.hubcluster-1.lab.eng.cert.redhat.com   Inspecting      true             74m

# â³ Wait for provisioned status...

master-3.mno-cu.hubcluster-1.lab.eng.cert.redhat.com   provisioned     true             74m
```

> **ğŸ“ Note:** The server will boot using Virtual Media to install RHCOS during the provisioning phase.

---

### ğŸ“œ Step 8: Approve Certificate Signing Requests

```bash
# ğŸ” Check for pending CSRs
$ oc get csr

# ğŸ“ Expected CSRs for new node
NAME        AGE   SIGNERNAME                                    REQUESTOR                                                                   REQUESTEDDURATION   CONDITION
csr-c9gcr   39m   kubernetes.io/kube-apiserver-client           system:node:master-3.mno-cu.hubcluster-1.lab.eng.cert.redhat.com            24h                 Approved,Issued
csr-gxdkl   41m   kubernetes.io/kube-apiserver-client-kubelet   system:serviceaccount:openshift-machine-config-operator:node-bootstrapper   <none>              Approved,Issued
csr-pdd7g   39m   kubernetes.io/kube-apiserver-client           system:node:master-3.mno-cu.hubcluster-1.lab.eng.cert.redhat.com            24h                 Approved,Issued
csr-q2fv5   40m   kubernetes.io/kubelet-serving                 system:node:master-3.mno-cu.hubcluster-1.lab.eng.cert.redhat.com            <none>              Approved,Issued
```

---

### ğŸ¤– Step 9: Create Machine Resource

```yaml
# ğŸ—ï¸ Create the machine CR to link BMH with cluster
cat <<EOF | oc apply -f -
apiVersion: machine.openshift.io/v1beta1
kind: Machine
metadata:
  annotations:
    metal3.io/BareMetalHost: openshift-machine-api/master-3.mno-cu.hubcluster-1.lab.eng.cert.redhat.com
  labels:
    machine.openshift.io/cluster-api-cluster: mno-cu-8wdjc 
    machine.openshift.io/cluster-api-machine-role: master
    machine.openshift.io/cluster-api-machine-type: master
  name: mno-cu-8wdjc-master-3
  namespace: openshift-machine-api
spec:
  metadata: {}
  providerSpec:
    value:
      apiVersion: baremetal.cluster.k8s.io/v1alpha1
      customDeploy:
        method: install_coreos
      hostSelector: {}
      image:
        checksum: ""
        url: ""
      kind: BareMetalMachineProviderSpec
      metadata:
        creationTimestamp: null
EOF
```

---

### ğŸ”— Step 10: Verify BMH-Machine Linking

```bash
# ğŸ” Check BMH consumer linkage
$ oc get bmh 
```

**Expected Output:**
```
NAME                                                   STATE         CONSUMER                ONLINE   ERROR   AGE
master-0.mno-cu.hubcluster-1.lab.eng.cert.redhat.com   unmanaged     mno-cu-8wdjc-master-0   true             4h50m
master-1.mno-cu.hubcluster-1.lab.eng.cert.redhat.com   unmanaged     mno-cu-8wdjc-master-1   true             4h50m
master-3.mno-cu.hubcluster-1.lab.eng.cert.redhat.com   provisioned   mno-cu-8wdjc-master-3   true             79m
```

```bash
# ğŸ¤– Verify machine status
$ oc get machine
```

**Expected Output:**
```
NAME                    PHASE     TYPE   REGION   ZONE   AGE
mno-cu-8wdjc-master-0   Running                          4h51m
mno-cu-8wdjc-master-1   Running                          4h51m
mno-cu-8wdjc-master-3   Running                          39m
```

---

### âœ… Step 11: Verify Node Status

```bash
# ğŸ¯ Check new node is ready
$ oc get nodes
```

**Expected Output:**
```
NAME                                                   STATUS   ROLES                         AGE     VERSION
master-0.mno-cu.hubcluster-1.lab.eng.cert.redhat.com   Ready    control-plane,master,worker   4h24m   v1.32.7
master-1.mno-cu.hubcluster-1.lab.eng.cert.redhat.com   Ready    control-plane,master,worker   4h46m   v1.32.7
master-3.mno-cu.hubcluster-1.lab.eng.cert.redhat.com   Ready    control-plane,master,worker   44m     v1.32.7
```

---

### ğŸ”’ Step 12: Re-enable Quorum Guard

```bash
# ğŸ›¡ï¸ Restore etcd quorum protection
oc patch etcd/cluster --type=merge -p '{"spec": {"unsupportedConfigOverrides": null}}'
```

---

## ğŸ§ª Final Validation

### ğŸ“Š Comprehensive System Health Check

#### ğŸ–¥ï¸ Node Status Verification

```bash
# âœ… Verify all nodes are ready
$ oc get nodes
```

```
NAME                                                   STATUS   ROLES                         AGE     VERSION
master-0.mno-cu.hubcluster-1.lab.eng.cert.redhat.com   Ready    control-plane,master,worker   4h24m   v1.32.7
master-1.mno-cu.hubcluster-1.lab.eng.cert.redhat.com   Ready    control-plane,master,worker   4h46m   v1.32.7
master-3.mno-cu.hubcluster-1.lab.eng.cert.redhat.com   Ready    control-plane,master,worker   44m     v1.32.7
```

#### ğŸ¤– Machine API Status

```bash
# ğŸ”§ Check machine API objects
$ oc get machine
$ oc get bmh 
```

#### ğŸŒ Cluster Operator Status

```bash
# ğŸ“Š Verify all cluster operators are healthy
$ oc get co
```

**Expected Output:** All operators should show `AVAILABLE=True`, `PROGRESSING=False`, `DEGRADED=False`

```
NAME                                       VERSION   AVAILABLE   PROGRESSING   DEGRADED   SINCE   MESSAGE
authentication                             4.19.10   True        False         False      4h24m   
baremetal                                  4.19.10   True        False         False      4h42m   
cloud-controller-manager                   4.19.10   True        False         False      4h47m   
...
```

#### ğŸ¥ Cluster Version Status

```bash
# ğŸ“ˆ Verify cluster version
$ oc get clusterversion
```

```
NAME      VERSION   AVAILABLE   PROGRESSING   SINCE   STATUS
version   4.19.10   True        False         4h26m   Cluster version is 4.19.10
```

#### ğŸ’“ ETCD Health Verification

```bash
# ğŸ” Check ETCD pods
$ oc get pods -n openshift-etcd
```

**Key Pods to Verify:**
```
etcd-guard-master-0.mno-cu.hubcluster-1.lab.eng.cert.redhat.com           1/1     Running     0          4h27m
etcd-guard-master-1.mno-cu.hubcluster-1.lab.eng.cert.redhat.com           1/1     Running     0          4h44m
etcd-guard-master-3.mno-cu.hubcluster-1.lab.eng.cert.redhat.com           1/1     Running     0          46m
etcd-master-0.mno-cu.hubcluster-1.lab.eng.cert.redhat.com                 5/5     Running     0          41m
etcd-master-1.mno-cu.hubcluster-1.lab.eng.cert.redhat.com                 5/5     Running     0          39m
etcd-master-3.mno-cu.hubcluster-1.lab.eng.cert.redhat.com                 5/5     Running     0          37m
```

#### ğŸ”— ETCD Member Status

```bash
# ğŸ“‹ Verify ETCD cluster membership
$ oc -n openshift-etcd rsh etcd-master-0.mno-cu.hubcluster-1.lab.eng.cert.redhat.com etcdctl member list -w table
```

**Expected Output:**
```
+------------------+---------+------------------------------------------------------+----------------------------+----------------------------+------------+
|        ID        | STATUS  |                         NAME                         |         PEER ADDRS         |        CLIENT ADDRS        | IS LEARNER |
+------------------+---------+------------------------------------------------------+----------------------------+----------------------------+------------+
| 3609a04589b18117 | started | master-3.mno-cu.hubcluster-1.lab.eng.cert.redhat.com | https://192.168.24.89:2380 | https://192.168.24.89:2379 |      false |
| 7ba70a5da2a758f8 | started | master-0.mno-cu.hubcluster-1.lab.eng.cert.redhat.com | https://192.168.24.87:2380 | https://192.168.24.87:2379 |      false |
| e9dca6063087aaf5 | started | master-1.mno-cu.hubcluster-1.lab.eng.cert.redhat.com | https://192.168.24.88:2380 | https://192.168.24.88:2379 |      false |
+------------------+---------+------------------------------------------------------+----------------------------+----------------------------+------------+
```

#### ğŸ’š ETCD Endpoint Health

```bash
# ğŸ’“ Final health check
$ oc -n openshift-etcd rsh etcd-master-0.mno-cu.hubcluster-1.lab.eng.cert.redhat.com etcdctl endpoint health
```

**Expected Output:**
```
https://192.168.24.88:2379 is healthy: successfully committed proposal: took = 7.967754ms
https://192.168.24.87:2379 is healthy: successfully committed proposal: took = 8.308346ms
https://192.168.24.89:2379 is healthy: successfully committed proposal: took = 11.115965ms
```

---

## ğŸ‰ Success Criteria

### âœ… Validation Checklist

- [ ] **ğŸ–¥ï¸ All 3 master nodes** showing `Ready` status
- [ ] **ğŸ¤– All machine objects** in `Running` phase  
- [ ] **ğŸ”§ All BMH objects** properly linked to machines
- [ ] **ğŸŒ All cluster operators** healthy (`AVAILABLE=True`, `DEGRADED=False`)
- [ ] **ğŸ’“ ETCD cluster** healthy with 3 members
- [ ] **ğŸ”— ETCD endpoints** all responding properly
- [ ] **ğŸ“ˆ Cluster version** stable and not progressing

### ğŸ† Completion Status

> **ğŸ¯ Result:** Control plane node replacement completed successfully!
> 
> **â±ï¸ Downtime:** Minimal - cluster remained operational throughout the process
> 
> **ğŸ”„ Recovery:** Full 3-node control plane restored with `master-3` replacing `master-2`

---

<div align="center">

### ğŸ”§ **Node Replacement Complete** ğŸ”§

![Success](https://img.shields.io/badge/Replacement-Successful-brightgreen?style=for-the-badge)
![ETCD](https://img.shields.io/badge/ETCD-Healthy-green?style=for-the-badge)
![Cluster](https://img.shields.io/badge/Cluster-Stable-blue?style=for-the-badge)

**ğŸ“š Documentation maintained by the OpenShift Platform Team**

</div>
